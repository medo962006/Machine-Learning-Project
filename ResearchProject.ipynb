{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from random import shuffle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "ok = False\n",
    "categories = ['Grass' , 'Asphalt' , 'Gravel' , 'Glass' , 'Bricks']\n",
    "test_directory = \"\"\n",
    "train_directory = \"\"\n",
    "#Texture images should be inside a folder named train where every category is under a folder with its name, for Training/Evaluation purposes \n",
    "directory = './train/textureImages'\n",
    "def training_data_initializer():\n",
    "    for category in categories:\n",
    "        path = directory+'/'+category\n",
    "        Image_category = categories.index(category)\n",
    "        for img in listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(f'{path}/{img}')\n",
    "                new_array = cv2.resize(img_array , (32 , 32))\n",
    "                if([new_array,Image_category] not in training_data):\n",
    "                    training_data.append([new_array , Image_category])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "training_data_initializer()\n",
    "\n",
    "shuffle(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for features , label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "X = np.array(X).reshape(-1 , 32 , 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , Y , test_size = 0.2 , random_state = 0)\n",
    "x_train = tf.stack(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "x_test = tf.stack(x_test)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).prefetch(16)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Adding new Datasets:-\n",
    "new_dataset_Path = \"\"\n",
    "new_training_data = []\n",
    "def training_data_initializer():\n",
    "    if new_dataset_Path != \"\":\n",
    "        for category in categories:\n",
    "            path = new_dataset_Path\n",
    "            Image_category = categories.index(category)\n",
    "            for img in listdir(path):\n",
    "                try:\n",
    "                    img_array = cv2.imread(f'{path}/{img}')\n",
    "                    new_array = cv2.resize(img_array , (32 , 32))\n",
    "                    if([new_array,Image_category] not in training_data):\n",
    "                        training_data.append([new_array , Image_category])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "training_data_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32 , 32 , 3)))\n",
    "model.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=84, activation='relu')) \n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=68, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, \n",
    "          validation_data= test_ds, \n",
    "          epochs = 80,\n",
    "          callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test,y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
